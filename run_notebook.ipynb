{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drive.mount(\"/content/gdrive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/gdrive/MyDrive/Git_rep/my_version/leo_segmentation')\n",
    "import sys, os, argparse, gc, time, numpy as np, tensorflow as tf, pandas as pd\n",
    "os.chdir(os.path.join(\"./leo_segmentation\"))\n",
    "from data_pytorch_pascal import Datagenerator, TrainingStats\n",
    "from leo_fomaml_latest import LEO, load_model, save_model\n",
    "from utils import load_config, check_experiment, get_named_dict, \\\n",
    "                        log_data, load_yaml, train_logger, val_logger, print_to_string_io, \\\n",
    "                        save_pickled_data, model_dir, list_to_tensor, numpy_to_tensor, prepare_inputs,\\\n",
    "                        tensor_to_numpy\n",
    "os.chdir('/content/gdrive/MyDrive/Git_rep/my_version/leo_segmentation')\n",
    "from run import train_model\n",
    "from matplotlib import pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"pascal_5i_fold_0\"\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leo = train_model(config, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"meta_val\"\n",
    "dataset =\"fss1000\"\n",
    "dataloader = Datagenerator(config, dataset, data_type=mode)\n",
    "img_transformer = dataloader.transform_image\n",
    "mask_transformer = dataloader.transform_mask\n",
    "transformers = (img_transformer, mask_transformer)\n",
    "val_meta_data = dataloader.get_batch_data()\n",
    "class_in_metadata = val_meta_data[4]\n",
    "print(f\"classes in mode {mode}: {class_in_metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_class = 1\n",
    "pred_data_index = list(range(5))\n",
    "print(\"class\", class_in_metadata[select_class], \"is selected\")\n",
    "batch_data = get_named_dict(val_meta_data, select_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform forward_propagate and perform innerloop updates to generate weights\n",
    "seg_weight_grad, features = leo.leo_inner_loop(batch_data.tr_imgs, batch_data.tr_masks)\n",
    "#fine tune the weights\n",
    "tr_val_loss, seg_weight_grad, decoder_grads, mean_iou, weight = \\\n",
    "            leo.finetuning_inner_loop(batch_data, features, seg_weight_grad, transformers, mode)\n",
    "\n",
    "#prepare validation set\n",
    "if type(pred_data_index) == list:\n",
    "    input_embedding = np.vstack([list_to_tensor(batch_data.val_imgs[i], img_transformer) \\\n",
    "                                 for i in pred_data_index])\n",
    "    input_mask = np.vstack([list_to_tensor(batch_data.val_masks[i], mask_transformer) \\\n",
    "                            for i in pred_data_index])\n",
    "else:\n",
    "    input_embedding = list_to_tensor(batch_data.val_imgs[pred_data_index], img_transformer)\n",
    "    input_mask = list_to_tensor(batch_data.val_masks[pred_data_index], mask_transformer)\n",
    "\n",
    "input_embedding_for_plot = input_embedding.copy()\n",
    "input_mask_for_plot = input_mask.copy()\n",
    "\n",
    "input_embedding = prepare_inputs(numpy_to_tensor(input_embedding))\n",
    "input_mask = numpy_to_tensor(input_mask)\n",
    "#predict on training data\n",
    "skip_features = leo.forward_encoder(input_embedding)\n",
    "features = leo.forward_decoder(skip_features)\n",
    "val_prediction = leo.forward_segnetwork(features, input_embedding, weight)\n",
    "val_prediction = np.argmax(tensor_to_numpy(val_prediction), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch_mask(embeds, preds, masks):\n",
    "    fig = plt.figure(figsize=(20,16))\n",
    "    for i in range(0, len(preds)):\n",
    "        embed = np.squeeze(embeds) if len(embeds) == 1 else embeds[i]\n",
    "        pred = np.squeeze(preds) if len(preds) == 1 else preds[i]\n",
    "        mask = np.squeeze(masks) if len(masks) == 1 else masks[i]\n",
    "        \n",
    "        fig.add_subplot(len(preds), 3, i*3+1)\n",
    "        plt.imshow((embed+1)/2)\n",
    "        plt.title(\"raw images\")\n",
    "        \n",
    "        fig.add_subplot(len(preds), 3, i*3+2)\n",
    "        plt.imshow(mask, cmap=\"gray\")\n",
    "        plt.title(\"ground_truth\")\n",
    "        \n",
    "        fig.add_subplot(len(preds), 3, i*3+3)\n",
    "        plt.imshow(pred, cmap=\"gray\")\n",
    "        plt.title(\"prediction\")\n",
    "        \n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_batch_mask(input_embedding_for_plot, val_prediction, input_mask_for_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_number = config.experiment.number\n",
    "experiment_description = config.experiment.description\n",
    "experiment_root_path = os.path.join(\"leo_segmentation\", \"data\", \"models\", f\"experiment_{experiment_number}\")\n",
    "cached_files = os.listdir(experiment_root_path)\n",
    "cached_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = cached_files[4]\n",
    "val_ious = pd.read_pickle(os.path.join(experiment_root_path, filename)).T\n",
    "print(f\"filename: {filename}\")\n",
    "filtered_scores = []\n",
    "for _class, _df in val_ious.iterrows():\n",
    "    if _class == \"episode\":\n",
    "        continue\n",
    "    temp = [i for i in _df if not np.isnan(i)]\n",
    "    class_sampling_frequency = len(temp)\n",
    "    mean_of_all_ious_per_class = np.mean(temp)\n",
    "    filtered_scores.append((_class, mean_of_all_ious_per_class, class_sampling_frequency))\n",
    "filtered_val_ious = pd.DataFrame(filtered_scores, columns=[\"classes\", \"mean_val_ious\", \"class_sampling_frequency\"])\n",
    "filtered_val_ious = filtered_val_ious.sort_values(by=\"mean_val_ious\", ascending=False)\n",
    "filtered_val_ious[filtered_val_ious.mean_val_ious > 0.7].count()\n",
    "filtered_val_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"leo_segmentation/data/fss1000/images\")[600:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_val_ious.class_sampling_frequency.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ious = pd.read_pickle(os.path.join(experiment_root_path, cached_files[2])).T\n",
    "filtered_scores = []\n",
    "for _class, _df in train_ious.iterrows():\n",
    "    if _class == \"episode\":\n",
    "        continue\n",
    "    temp = [i for i in _df if not np.isnan(i)]\n",
    "    class_sampling_frequency = len(temp)\n",
    "    mean_of_all_ious_per_class = np.mean(temp)\n",
    "    filtered_scores.append((_class, mean_of_all_ious_per_class, class_sampling_frequency))\n",
    "filtered_train_ious = pd.DataFrame(filtered_scores, columns=[\"classes\", \"mean_train_ious\", \"class_sampling_frequency\"])\n",
    "filtered_train_ious = filtered_train_ious.sort_values(by=\"mean_train_ious\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes in meta-train and meta-val are unique if their intersection is zero\n",
    "set(filtered_train_ious.classes.unique()).intersection(set(filtered_val_ious.classes.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_val_loss = pd.read_pickle(os.path.join(experiment_root_path, cached_files[5]))\n",
    "meta_train_loss = pd.read_pickle(os.path.join(experiment_root_path, cached_files[3]))\n",
    "num_data_points = meta_val_loss.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "plt.title(\"meta_losses\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(np.arange(num_data_points), meta_val_loss.total_val_loss, label=\"meta_val_loss\")\n",
    "plt.plot(np.arange(num_data_points), meta_train_loss.total_val_loss, label=\"meta_train_loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"leo_segmentation/data/models/experiment_15\"\n",
    "cached_files = os.listdir(results_path)\n",
    "cached_files = {i:k for i,k in enumerate(cached_files)}\n",
    "cached_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_pickle(os.path.join(results_path, cached_files[4]))\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "for i in range(5):\n",
    "    plt.plot(result_df.iloc[:,i], label=result_df.columns[i])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_df = pd.read_pickle(os.path.join(results_path, cached_files[2]))\n",
    "train_results_df.fillna(0.0).max().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_per_col={}\n",
    "for i in range(len(train_results_df.columns)):\n",
    "    if train_results_df.columns[i] == \"episode\":\n",
    "        continue\n",
    "    temp = train_results_df.iloc[:,i]\n",
    "    temp = temp.dropna()\n",
    "    counts_per_col[train_results_df.columns[i]] = len(temp)\n",
    "pd.Series(counts_per_col).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "plt.plot(pd.read_pickle(os.path.join(results_path,\n",
    "            cached_files[3]))[\"total_val_loss\"], label=\"train\")\n",
    "plt.plot(pd.read_pickle(os.path.join(results_path,\n",
    "            cached_files[5]))[\"total_val_loss\"], label=\"val\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
